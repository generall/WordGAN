import os
import re
from unittest import TestCase

import torch

from word_gan.model.embedding_to_word import EmbeddingToWord
from word_gan.settings import DATA_DIR


def remove_prefix(model_state: dict):
    res = {}

    for key, val in model_state.items():
        key = re.sub(r'^\w+\.', '', key)
        res[key] = val
    return res


class TestWordReconstruction(TestCase):
    def test_word_reconstruction(self):
        vect_permanently = torch.tensor(list(map(
            float,
            '0.350045 -0.802001 -0.143020 -0.073151 -0.448331 -0.198608 0.452894 -0.423483 -0.199338 0.052744 '
            '-0.097778 -0.281163 -0.179313 0.115126 -0.149038 -0.227457 -0.561052 0.478153 0.049413 0.092480 '
            '0.001625 -0.225345 -0.451424 0.025747 0.092592 -0.228965 -0.032949 0.664025 0.007891 0.038191 '
            '-0.192894 -0.043159 -0.431111 0.075395 -0.412713 -0.374102 0.218199 -0.338118 0.495967 0.225025 '
            '0.304354 -0.124257 -0.077302 -0.041383 -0.058369 -0.457834 0.452378 -0.154916 0.217938 -0.382635 '
            '-0.093978 -0.071119 -0.220260 0.178645 -0.473302 -0.030217 -0.063702 -0.438322 0.004423 -0.276251 '
            '-0.497187 0.120985 0.140026 0.125765 -0.000368 0.148719 0.247363 0.168362 -0.302344 0.155667 0.566196 '
            '0.489412 -0.203638 -0.089439 -0.190128 0.323852 -0.522398 -0.459006 -0.424616 0.264934 0.747471 '
            '0.202642 -0.235539 -0.140542 -0.549982 0.465064 0.339117 0.318824 -0.139908 0.222711 -0.219051 '
            '0.452325 -0.223175 0.673869 0.014414 -0.146003 -0.312173 -0.067005 -0.225620 -0.599278 -0.254912 '
            '-0.540395 -0.642863 0.136958 -0.123835 -0.289301 0.352934 0.450540 0.273166 -0.233267 0.341970 '
            '-0.225688 -0.199903 0.253406 -0.075347 -0.558593 0.464780 -0.250060 0.058880 -0.460803 -0.085354 '
            '0.228973 0.513727 -0.706610 0.183285 -0.457987 0.263284 0.153468 0.294248 0.196702 -0.809882 '
            '-0.509054 -0.085856 -0.262591 0.426603 0.228298 0.129609 -0.346098 0.063438 -0.169333 0.008942 '
            '0.194020 0.625724 0.072331 -0.324798 -0.334132 -0.312798 -0.321535 0.120674 -0.054717 -0.201681 '
            '-0.276259 -0.742715 -0.251345 -0.023129 0.171352 1.028290 -0.428043 -0.306133 -0.277357 0.169573 '
            '0.291584 0.010770 -0.012234 0.000285 0.480301 0.254376 -0.718296 -0.295183 0.420335 -0.161289 '
            '0.206060 -0.620754 0.018280 0.456110 -0.795565 -0.225452 -0.135951 0.519771 -0.120920 -0.059389 '
            '0.016158 0.158619 0.107235 0.306941 0.391693 0.644735 -0.119743 -0.050605 -0.440215 -0.048190 '
            '-0.375253 0.216008 -0.231695 0.400879 0.052431 0.111908 -0.413177 0.089826 -0.074499 -0.157998 '
            '0.138070 0.392816 -0.282308 0.122140 -0.277127 0.320189 -0.229146 -0.047533 -0.103422 0.200335 '
            '-0.424784 -0.189848 -0.153841 0.339968 0.044723 0.285108 0.164212 0.022879 0.182577 -0.417396 '
            '-0.423130 -0.271177 -0.323613 0.212195 0.264430 0.584048 0.421788 -0.245208 -0.384946 0.027946 '
            '-0.435558 -0.215985 -0.309872 0.037690 0.263239 0.206339 -0.267221 0.252363 0.519289 -0.531044 '
            '-0.154478 0.098545 0.019198 0.048495 0.120135 0.032396 0.461493 -0.834265 -0.030504 -0.035046 '
            '-0.329691 0.013960 0.659091 -0.480449 0.406292 0.239894 0.359734 -0.396988 -0.279392 -0.505935 '
            '-0.135511 -0.554490 -0.152101 -0.047955 0.356637 -0.387952 0.473839 -0.409795 -0.376406 -0.616158 '
            '-0.411500 -0.458381 0.491061 -0.215422 0.053055 -0.485235 0.057944 0.028049 -0.149408 0.881606 '
            '0.160568 0.000189 -0.090455 0.214743 -0.504232 0.703072 0.199228 0.091627 -0.498764 -0.154078 '
            '-0.093004 0.263828 -0.361898 0.417493 -0.482641 0.335341 0.088338 -0.357832 0.283778'.split())))

        weights_file = os.path.join(DATA_DIR, 'v2w_model.th')
        model_state = torch.load(weights_file, map_location=torch.device('cpu'))
        model_state = remove_prefix(model_state)

        model: torch.nn.Module = EmbeddingToWord(embedding_size=300, words_count=100_000 + 2)

        model.load_state_dict(model_state)

        word_scores = model(vect_permanently)

        print("word_scores: ", word_scores)

        print("Shape:", word_scores.shape)

        word_score, word_idx = torch.max(word_scores, dim=0)

        print('Index: ', word_idx, 'score', word_score)

        print('Close scores count:', (word_scores > -10).sum())
